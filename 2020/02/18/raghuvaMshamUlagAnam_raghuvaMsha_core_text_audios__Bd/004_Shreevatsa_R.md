+++
title = "004 Shreevatsa R"

+++
[[Shreevatsa R	2020-02-19, 00:31:25 [Source](https://groups.google.com/g/bvparishat/c/BdNVYYNIQEk)]]



On Tue, 18 Feb 2020 at 03:04, विश्वासो वासुकेयः \<[vishvas...@gmail.com]()\> wrote:  

> 
> > > 
> > > > 
> > > > 2\. Has there been any experiment to synthesize shlokas using > > standard recordings for phonemes? > > > > 
> > > > 
> > 
> >   
> > 
> > 
> > <https://github.com/sanskrit-coders/indic_text_to_speech> इत्यनेन > प्रयत्तम् इषत्, न तावत्सफलम्। मसृणता न भवति ध्वनौ। >
> 
> > 

  

I can't figure out from the repository -- in what way does it use these standard recordings? I don't knowmuch about the area but I imagine that it would first require a correspondence between the audio in the recordings and the corresponding text... does that exist already? If not, that seems like a first step that would be useful on its own.

  

(Oh, on re-reading, I think the question may have been interpreted as "standard recordings for each phoneme, made independently" -- yes simply concatenating the sound of each syllable will not result in something natural sounding. But I imagine that with say the \~56 hours of [Ramayana recitation](https://archive.org/details/Ramayana-recitation-Sriram-harisItArAmamUrti-Ghanapaati-v2) or the \~7 hours here, it may be possible to learn more features and learn at least how to synthesize something in a particular style, for a particular metre, etc? I don't know anything about ML, let alone ML for audio, so I don't know how feasible this is... but seems like a project that would be useful.)  

