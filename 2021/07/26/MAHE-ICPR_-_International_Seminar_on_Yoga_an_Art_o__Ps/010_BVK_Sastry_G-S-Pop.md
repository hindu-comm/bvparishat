+++
title = "010 BVK Sastry (G-S-Pop)"

+++
[[BVK Sastry (G-S-Pop)	2021-07-28, 12:21:38 [Source](https://groups.google.com/g/bvparishat/c/PsqqMMb5MwA)]]



Namaste



On \< न गू॑गलनु॒वाद॑केन॒ कोऽपि॑ शब्दको॒शः प्रयु॑ज्यते। Google Translate does not use any lexicon-database. >



Such naïve assumptions without peeping deep in to the ‘inherited dependencies on ‘lexicon –data base’ approach ‘ and pedagogic challenges’ need serious correction. !

Google , no doubt serves a limited and specific purpose, useful for society and work. That does not make ‘ Google’ a ‘ human –brain-process- language-meaning provider- substitute’. Has Google MT/ Neural networks design comprehended the tonal accent marker implications ? Still work in progress.



If there are indigenous initiatives for ‘ Panini- Language Modelling’ we need to consolidate the team. As far as I understand there is the initiative called SOIL ( Samskruth Operative System for Indian Language )- again a work in progress at SCCI ( supercomputing consortium of India).



1. On Translation – Tradition of Brahmi- Indic language/ Samskruth sentences, the traditional thinking and process is different from statistical picks of meaning : 



संस्कृत-भाषा-विषयक - वाक्य-प्रयोगाणां वाक्यार्थ- तात्पर्यार्थ-
अनुवादार्थं / अवगननार्थं / अवबोधार्थं / जिज्ञासार्थं / उपासनार्थं -
वाक्य-घटित-पदानां अर्थावगतिः प्रथमः सोपान: । पदार्थावगतिः पदशास्त्रं- वाग्योगः- वेदाङ्गः - इति प्रसिद्धस्य षडङ्गान्तर्गत- व्याकरण सरण्या कारकान्वय-समन्वयात् - प्रथमतया साधनीयः ।

पदार्थ-निर्वचनं- पदार्थ-निरुक्तिः इति एषा प्रक्रिया परिभाषिता । एतेषामवगमनार्थं पाणिनि-पदशास्त्र- विज्ञानं अन्यथैव पाठनीयं भवति ।

तच्च संशोधन-विषयमिति सामाजिक-जाल-माध्यमे न प्रस्तूयते।



2. On \< Google Translate does not use any lexicon-database. \> 

Please explore the origination of deep dependencies
inherited and ‘DNA integrated to MT and A.I systems architecture’, going deep back by several decades in HMI

Interface designs and A.I deliberations. This issue is technically researched as ‘Human- Language Modelling’ part of ‘ Language-Technology’, under HMI /AI designs. This has been messed up by ‘Techno-linguists, who are driving a force-fitment of ‘Paninian Brahmi Language to Roman –English like frame work.

Word tinkering and soft language does not take away the defect or correct the damage. 



Simple two statements :

1.1. Google can’t write for an audience. \[[How Google Translate Works and Why It Doesn't \| Transparent Language Blog](https://blogs.transparent.com/language-news/2015/09/02/how-google-translate-works-and-why-it-doesnt-measure-up/)
\] 



1.2. Techno-linguists cannot but do a force-fit of human language to the constraints of given OS and programming language frame work; It is a
covenant through corporate – commercial – commitment. Even when they know fully well in their heart and conscience that ‘ human language is dismembered in such process’. More so when it comes with ‘ Panini-Targeting’.



1.2.A) - [Google Translate](http://translate.google.com/translate?&langpair=de%7Cfr&u=http://en.wikipedia.org/wiki/Google_Translate)
<http://translate.google.com/translate?&langpair=de%7Cfr&u=http://en.wikipedia.org/wiki/Google_Translate>
Originally centred around statistical machine translation,**Google****Translate****worked**by translating the required text first into English as an intermediary step language and then into the target language, cross-referencing the phrase in question with millions of documents taken from official United Nations and European Parliament transcripts.



1.2.B) The current ‘ released model of Google Translate’ is 47th stage (launched February 2021) – covering : Speech program launched in Afrikaans, Bulgarian, Catalan, Icelandic, Latvian, and Serbian (changed from eSpeak to a natural voice). New speech system (WaveNet) for several languages.



 What is wavenet ? - <https://en.wikipedia.org/wiki/WaveNet> - WaveNet is a deep neural network for generating raw audio. It was created by researchers at London-based artificial intelligence firm DeepMind. The technique, outlined in a paper in September 2016,is able to generate relatively realistic-sounding human-like voices by directly modelling waveforms using a neural network method trained with recordings of real speech. Tests with US English and Mandarin reportedly **showed that the system outperforms Google's best existing text-to-speech (TTS)** systems, although as of 2016 its text-to-speech synthesis still was less convincing than actual human speech. WaveNet's ability to generate raw waveforms means that it can model any kind of audio, including music.



1.2.C) What drives this research ? – Talking Machines/ thinking Machines which may replace ‘ human dependency’ or ‘ replace humans’ . [WaveNet: A generative model for raw audio \| DeepMind](https://deepmind.com/blog/article/wavenet-generative-model-raw-audio) - Knowing What to Say : In order to use WaveNet to turn text into speech, we have to tell it what the text is. We do this by transforming the text into a sequence of linguistic and phonetic features (which contain information about the current phoneme, syllable, word, etc.) and by feeding it into WaveNet. This means the network’s predictions are conditioned not only on the previous audio samples, but also on the text we want it to say. If we train the network without the text sequence, it still generates speech, but now it has to make up what to say. As you can hear from the samples below, this results in a kind of babbling, where real words are interspersed with made-up word-like sounds:



Regards

BVK Sastry



**From:** [bvpar...@googlegroups.com]() \[mailto:[bvpar...@googlegroups.com]()\] **On Behalf Of** ??????? ??????  
**Sent:** 28 July 2021 08:04  
**To:** भारतीयविद्वत्परिषत्  
**Subject:** Re: {भारतीयविद्वत्परिषत्} Re: MAHE-ICPR - International Seminar on Yoga an Art of Equanimity and Agency - 26 July 2021, 7PM (IST)



> 
> > 
> > Human Language- Meaning Process Modelling in Machine Translation > systems –pedagogy is short scaled in heavily depending on ‘ lexicon > –data base’ approach. >
> 
> > 

न गू॑गलनु॒वाद॑केन॒ कोऽपि॑ शब्दको॒शः प्रयु॑ज्यते।

Google Translate does not use any lexicon-database.

--  

You received this message because you are subscribed to the Google Groups "भारतीयविद्वत्परिषत्" group.  
To unsubscribe from this group and stop receiving emails from it, send an email to [bvparishat+...@googlegroups.com]().  

To view this discussion on the web visit [https://groups.google.com/d/msgid/bvparishat/35f615b3-65a0-416b-9924-9ce1e2450b22n%40googlegroups.com](https://groups.google.com/d/msgid/bvparishat/35f615b3-65a0-416b-9924-9ce1e2450b22n%40googlegroups.com?utm_medium=email&utm_source=footer).

